\newpage

\section{Вступ}

Проблема побудови автоматичих контролерів для роботів або інших складних механізмів була серйозним викликом для вчених та інженерів з перших днів комп'ютерної ери і залишається не менш складною і сьогодні. Дуже часто постановка задачі контролю звучить наступним чином: \emph{``Для досягнення мети агент повинен взаємодіяти з зовнішнім середовищем, виконуючи дії з множини допустимих дій. Яка буде оптимальна послідовність дій для досягнення поставленої мети?''} Простота постановки задачі оманлива. Навчити штучні машини повторювати людську поведінку, діяти логічно та ефективно у будь-якій ситуації, як виявилося, надзвичайно складно. Було розроблено безліч технік та методик, які намагаються вирішити дану проблему з більшим або меншим успіхом.

Ця робота є спробою застосувати одну з таких методик, а саме "--- навчання з підсиленням з використанням штучних нейронних мереж, для розв'язання задачі оптимального керування роботом в умовах сереодвища, заповненого перешкодами.

У парадигмі навчання з підсиленням, агенту дається можливість експериментувати з множиною допустимих дій для вироблення оптимальної стратегії шляхом проб та помилок. Якість вибраних дій підкріплюється через систему винагород та покарань, яка базується на результатах вибраних дій. Даючи більшу винагороду за дії, що наближають агента до мети та караючи за ті, що призводять до неефективного розв'язку, агент отримує можливість оцінити власну поведінку. В результаті численних повторень агентом буде вироблена оптимальна стратегія, яка найефективніше приводить до виконання завдання.

